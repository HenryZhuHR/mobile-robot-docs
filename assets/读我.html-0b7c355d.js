import{_ as t,r as l,o as i,c as d,a as e,d as n,b as s,e as o}from"./app-7b5e955f.js";const r={},c=o(`<h2 id="依赖" tabindex="-1"><a class="header-anchor" href="#依赖" aria-hidden="true">#</a> 依赖</h2><p>按照如下创建环境并安装依赖环境，不要安装过高的版本，不然报错</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>conda create <span class="token parameter variable">-n</span> yolov5-export <span class="token assign-left variable">python</span><span class="token operator">=</span><span class="token number">3.8</span> <span class="token parameter variable">-y</span>
conda activate yolov5-export
conda deactivate
conda remove <span class="token parameter variable">-n</span> yolov5-export <span class="token parameter variable">--all</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>pip <span class="token function">install</span> <span class="token assign-left variable">numpy</span><span class="token operator">==</span><span class="token number">1.18</span>.5 <span class="token assign-left variable">protobuf</span><span class="token operator">==</span><span class="token number">3.20</span>.1 <span class="token assign-left variable">onnx</span><span class="token operator">==</span><span class="token number">1.9</span>.0 onnx-simplifier<span class="token operator">==</span><span class="token number">0.3</span>.6 yapf
pip <span class="token function">install</span> <span class="token assign-left variable">torch</span><span class="token operator">==</span><span class="token number">1.8</span>.2 <span class="token assign-left variable">torchvision</span><span class="token operator">==</span><span class="token number">0.9</span>.2 <span class="token assign-left variable">torchaudio</span><span class="token operator">==</span><span class="token number">0.8</span>.2 --extra-index-url https://download.pytorch.org/whl/lts/1.8/cu111
pip <span class="token function">install</span> pycuda<span class="token operator">&lt;</span><span class="token number">2021.1</span> nvidia-pyindex nvidia-tensorrt
pip <span class="token function">install</span> <span class="token parameter variable">-r</span> requirements.txt
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,4),p={href:"https://github.com/ultralytics/yolov5/issues/8012",target:"_blank",rel:"noopener noreferrer"},u=e("code",null,"numpy==1.18.5 protobuf==3.20.1",-1),h=o(`<h2 id="训练" tabindex="-1"><a class="header-anchor" href="#训练" aria-hidden="true">#</a> 训练</h2><h3 id="配置训练" tabindex="-1"><a class="header-anchor" href="#配置训练" aria-hidden="true">#</a> 配置训练</h3><p>在 <code>data</code> 文件下配置数据集（参考 <code>data/drink.yaml</code>），需要注意的是：</p><ol><li>数据集采用相对路径表示，路径 <code>&lt;path&gt;/&lt;train&gt;</code> 的组合，如果不配置 <code>&lt;path&gt;</code> 那么需要直接写全 <code>&lt;train&gt;/&lt;val&gt;</code> 的路径</li><li>也可以通过 <code>.txt</code> 文件建立数据集，这个方法，之后会补充</li></ol><p>对于数据集，建议统一放在 <code>~/datasets</code> 下便于管理，然后通过建立软链接放在 <code>data</code> 目录下</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token function">ln</span> <span class="token parameter variable">-s</span> ~/datasets/drink ./data/
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h3 id="训练模型" tabindex="-1"><a class="header-anchor" href="#训练模型" aria-hidden="true">#</a> 训练模型</h3><p>根据 <code>train.py</code> 修改训练参数后，再进行训练</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token function">bash</span> train.sh
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h2 id="部署" tabindex="-1"><a class="header-anchor" href="#部署" aria-hidden="true">#</a> 部署</h2><h3 id="模型转换" tabindex="-1"><a class="header-anchor" href="#模型转换" aria-hidden="true">#</a> 模型转换</h3><p>修改运行参数，主要是 <code>--data</code> 和 <code>--weights</code>，转换模型</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token function">bash</span> export.sh
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div>`,13),b=e("li",null,[e("code",null,"--include"),n(" 参数，是需要导出的模型类型")],-1),v=e("code",null,"--opset",-1),m=e("code",null,"--simplify",-1),k=e("code",null,"opset",-1),g={href:"https://github.com/ultralytics/yolov5/issues/6401",target:"_blank",rel:"noopener noreferrer"},_=e("code",null,"simplify",-1),f=o(`<blockquote><p>先做到这一步吧，用 onnx 推理， tensorrt 有 bug 还没解决， onnx 速度也还可以</p></blockquote><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>Infer with ONNXRuntime: <span class="token number">47.61075973510742</span> ms
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>python3 <span class="token parameter variable">-m</span> onnxsim <span class="token punctuation">\\</span>
    runs/train/exp/weights/best.onnx <span class="token punctuation">\\</span>
    runs/train/exp/weights/best-sim.onnx

python3 export-engine.py
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="推理" tabindex="-1"><a class="header-anchor" href="#推理" aria-hidden="true">#</a> 推理</h3><p>推理的代码在 <code>detector</code> 目录下，需要修改</p><ul><li><code>detector/drink.txt</code>: 数据集文件</li><li><code>detector/yolov5s-drink.onnx</code>: 导出的模型文件</li></ul><p>修改推理代码 <code>infer.py</code> ，然后运行</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>python3 infer.py
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>输出图像在 <code>images/image_ort.png</code> ，结果为</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>Infer with ONNXRuntime: <span class="token number">44.52037811279297</span> ms
result <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">53</span>, <span class="token number">198</span>, <span class="token number">191</span>, <span class="token number">614</span><span class="token punctuation">]</span>, <span class="token number">0</span>, <span class="token string">&#39;cola&#39;</span>, <span class="token number">0.7179150581359863</span><span class="token punctuation">)</span>, <span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><code>[53, 198, 191, 614]</code>: 坐标</li><li><code>0</code>: 类别序号</li><li><code>cola</code>: 类别名</li><li><code>0.7179150581359863</code>: 置信度</li></ul><p>请把 <em>类别序号</em> 传至串口，然后发送给控制板子</p><p>将 <code>detector</code> 目录和 <code>infer.py</code> 文件一起打包放到 Jetson Nano 上跑，跑通不报错即可</p><p>部署的时候在 Jetson Nano 不需要安装太多依赖，只需要保证安装下面的即可</p><ul><li><code>numpy</code></li><li><code>opencv-python</code></li><li><code>onnxruntime-gpu</code> : 这个的安装可能需要百度一下 Jetson Nano 上安装 onnxruntime-gpu ，不是gpu 没法加速</li></ul><p>About Jetson Nano</p>`,16),x={href:"https://developer.nvidia.com/embedded/downloads#?tx=$product,jetson_nano",target:"_blank",rel:"noopener noreferrer"},y={href:"https://developer.nvidia.com/embedded/jetpack-sdk-461",target:"_blank",rel:"noopener noreferrer"};function N(w,J){const a=l("ExternalLinkIcon");return i(),d("div",null,[c,e("blockquote",null,[e("p",null,[e("a",p,[n("issue#8012"),s(a)]),n(" 要求 "),u])]),h,e("ul",null,[b,e("li",null,[v,n(" 和 "),m,n("是导出 onnx 模型的参数，"),k,n(" 是算子的版本，有一个 "),e("a",g,[n("issue"),s(a)]),n(" 和这个相关； "),_,n(" 则是和 engine 相关的参数")])]),f,e("ul",null,[e("li",null,[e("a",x,[n("Jetson Nano 镜像"),s(a)])]),e("li",null,[e("a",y,[n("Jetpack 4.6.1"),s(a)])])])])}const I=t(r,[["render",N],["__file","读我.html.vue"]]);export{I as default};
